
# Radar Thoughtworks

## Técnicas e Tendências

A lista apresenta diversas técnicas e tendências atuais na área de tecnologia, sendo muitas delas de grande relevância. Achei particularmente interessante a *Geração Aumentada por Recuperação* (RAG), que melhora a qualidade de respostas de modelos de linguagem ao usar documentos recuperados como contexto, e a *Geração Automática de Descritores de Entidade Backstage*, que automatiza processos de catalogação, facilitando o trabalho das equipes. Além disso, o tópico sobre *Combinação de PLNs Tradicionais com LLMs* mostra que, em alguns casos, técnicas mais simples são mais eficientes que o uso de modelos mais avançados. Destacam-se ainda a *Conformidade Contínua*, que otimiza verificações de segurança, e as *Funções de Edge*, que diminuem a latência ao executar código próximo à pessoa usuária. Em contrapartida, há alertas sobre o uso excessivo de *LLMs* e *Fine-tuning* indiscriminado, apontando que muitas vezes existem alternativas mais econômicas e eficazes.

### Geração Aumentada por Recuperação (RAG)
Melhora a qualidade das respostas de modelos de linguagem ao usar documentos recuperados como contexto.

### Geração Automática de Descritores de Entidade Backstage
Automatiza processos de catalogação, facilitando o trabalho das equipes.

### Combinação de PLNs Tradicionais com LLMs
Mostra que técnicas mais simples podem ser mais eficientes do que modelos avançados.

### Conformidade Contínua
Otimiza verificações de segurança.

### Funções de Edge
Reduzem a latência ao executar código próximo à pessoa usuária.

### Alertas
- **Uso Excessivo de LLMs**: Pode haver alternativas mais econômicas e eficazes.
- **Fine-tuning Indiscriminado**: Muitas vezes existem alternativas mais eficientes.

## Tecnologias Emergentes e Estabelecidas

O texto aborda tópicos de tecnologias emergentes e estabelecidas, com ênfase em eventos, computação em nuvem, contêineres e aprendizado de máquina. Achei interessante a **CloudEvents**, que visa padronizar o formato de eventos entre plataformas, facilitando a interoperabilidade. Também foi fascinante o crescimento do **Arm na nuvem**, proporcionando maior eficiência e economia de custos. O **Azure OpenAI** destaca o uso de modelos GPT com segurança e conformidade integradas ao Azure, ideal para empresas que já usam a plataforma. A adoção de contêineres também é explorada, com o **Aplicativos de Contêiner do Azure** se destacando por simplificar o uso de Kubernetes. Finalmente, o **Pulumi** aparece como uma poderosa ferramenta de infraestrutura como código, uma alternativa ao Terraform. Esses avanços, junto com a integração de aprendizado de máquina com plataformas como **Weights & Biases**, tornam-se cada vez mais atraentes para o desenvolvimento e observabilidade de sistemas modernos.

### CloudEvents
Visa padronizar o formato de eventos entre plataformas, facilitando a interoperabilidade.

### Arm na Nuvem
Proporciona maior eficiência e economia de custos.

### Azure OpenAI
Destaca o uso de modelos GPT com segurança e conformidade integradas ao Azure.

### Aplicativos de Contêiner do Azure
Simplifica o uso de Kubernetes.

### Pulumi
Uma alternativa ao Terraform para infraestrutura como código.

### Weights & Biases
Integra aprendizado de máquina com plataformas para desenvolvimento e observabilidade.

## Ferramentas e Frameworks Recomendados

É apresentada uma seleção de ferramentas e tecnologias recomendadas pela Thoughtworks para otimização de processos de desenvolvimento e operação de software. Destacam-se ferramentas para testes e conformidade de APIs, como o **42Crunch API Conformance Scan**, que valida discrepâncias entre a documentação e a implementação real das APIs. O **actions-runner-controller** e o **runner auto-hospedado para GitHub Actions da Philips** facilitam o gerenciamento de runners em Kubernetes e AWS EC2. O **Contêiner do Emulador Android** simplifica testes de aplicativos Android, enquanto o **AWS CUDOS** monitora e otimiza gastos na AWS. Outras ferramentas, como o **GitHub Copilot** e **Gradio**, aprimoram o desenvolvimento com assistentes de código e interfaces para modelos de ML. O **Terrascan** e o **Velero** são destacados para segurança de IaC e backup de Kubernetes, respectivamente. Essas ferramentas visam aumentar a eficiência e segurança no desenvolvimento e operações de software.

além disso é apresentado uma variedade de ferramentas e frameworks recomendados pela Thoughtworks, focando em otimização e inovação no desenvolvimento de software. O **Astro** destaca-se por renderizar HTML no servidor, reduzindo o uso de JavaScript e melhorando a performance com sua arquitetura de ilhas. **DataComPy** facilita a comparação detalhada de DataFrames em Python, ideal para análise de dados. **Pinia** é um framework de gerenciamento de estado para Vue.js, oferecendo uma API mais simples que o Vuex. **Ray** é um framework para escalar código Python e IA em clusters, útil para treinamento e inferência de modelos de ML. **Android Adaptability** e **Electric** são focados em melhorar o desempenho e sincronização em aplicativos móveis, enquanto **Concrete ML** e **LiteLLM** se concentram em privacidade e integração com LLMs. Por fim, **vLLM** é um motor de inferência eficiente para LLMs, e **Zig** oferece uma alternativa robusta ao C, com vantagens na compi

### Astro
Renderiza HTML no servidor, reduzindo o uso de JavaScript e melhorando a performance com sua arquitetura de ilhas.

### DataComPy
Facilita a comparação detalhada de DataFrames em Python.

### Pinia
Framework de gerenciamento de estado para Vue.js, com uma API mais simples que o Vuex.

### Ray
Framework para escalar código Python e IA em clusters, útil para treinamento e inferência de modelos de ML.

### Android Adaptability
Melhora o desempenho de aplicativos móveis ao lidar com variações térmicas.

### Electric
Facilita o desenvolvimento de aplicativos móveis e web com sincronização local-first.

### Concrete ML
Permite aprendizado de máquina com preservação de privacidade usando criptografia homomórfica.

### LiteLLM
Simplifica a integração com APIs de modelos de linguagem de grande porte (LLMs).

### vLLM
Motor de inferência eficiente para LLMs, com suporte a modelos grandes e escalabilidade.

### Zig
Oferece uma alternativa robusta ao C, com vantagens na compilação cruzada e alocação de memória.

## Conclusão

A lista apresentada pela Thoughtworks oferece uma visão abrangente e inovadora sobre as tecnologias e ferramentas mais recentes e relevantes no campo do desenvolvimento de software. A combinação de técnicas avançadas, como Geração Aumentada por Recuperação e ferramentas emergentes, como o Astro e o Ray, evidencia um avanço significativo na eficiência e na capacidade de escalar sistemas modernos. Estou particularmente interessado em adotar essas soluções, pois elas prometem não apenas otimizar o desenvolvimento, mas também melhorar a performance e a segurança das aplicações. As técnicas e ferramentas discutidas têm o potencial de transformar a forma como abordamos o desenvolvimento e a operação de software, e estou ansioso para explorar e implementar essas inovações em projetos futuros.
